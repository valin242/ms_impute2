---
title: "R Notebook"
output: html_notebook
---

# Proteomics Data Analysis - Part 1: R Script

Description: Loads proteomics data, performs QC and normalization, simulates missing data (MCAR, MAR, MNAR) and saves datasets as CSV files for Python analysis.

# 1. Load Libraries

Ensure required packages are installed: install.packages(c("BiocManager")) BiocManager::install("MSnbase")

```{r}
library(data.table)
library(MSnbase)
library(stats)       # For median, mean
library(utils)       # For write.csv
```

# 2. Configuration

!!! USER ACTION REQUIRED: Specify paths and parameters !!!

```{r}
RAW_DATA_FILE <- "data/proteinGroups.csv" # E.g., MaxQuant proteinGroups.csv
OUTPUT_DIR <- "results/R" # Directory to save CSV files
SAMPLE_METADATA_FILE <- "data/sample_metadata.txt" # File mapping samples to conditions (optional, for creating MSnSet)
INTENSITY_COLUMNS_PATTERN <- "Intensity P" # Adjust based on your column names for intensities
CONTAMINANT_MARKER <- "+" # Marker for contaminants in protein IDs (e.g., from MaxQuant)
REVERSE_MARKER <- "+" # Marker for reverse sequences (e.g., from MaxQuant)

# Create output directory if it doesn't exist
if (!dir.exists(OUTPUT_DIR)) {
  dir.create(OUTPUT_DIR, recursive = TRUE)
}
```

# 3. Import Proteomics Data

```{r}
# Read the main data file
cat("Loading raw data from:", RAW_DATA_FILE, "\n")
prot_data <- fread(RAW_DATA_FILE)

# Identify intensity columns
intensity_cols <- grep(INTENSITY_COLUMNS_PATTERN, colnames(prot_data), value = TRUE)
if (length(intensity_cols) == 0) {
  stop("No intensity columns found matching the pattern: ", INTENSITY_COLUMNS_PATTERN)
}
cat("Found", length(intensity_cols), "intensity columns.\n")
print(colnames(prot_data))
```

```{r}
# Extract expression matrix (log2 transform often recommended for label-free proteomics)
# Assuming 0s should be treated as NAs before log transformation
expr_matrix <- as.matrix(prot_data[, ..intensity_cols])
expr_matrix[expr_matrix == 0] <- NA
expr_matrix_log2 <- log2(expr_matrix)
rownames(expr_matrix_log2) <- prot_data$`Protein IDs` # Or another unique identifier column
```

# 4. Create MSnSet Object

## Requires experimental design/metadata file.

### Format: A simple text file with sample names (matching intensity columns) and associated conditions/metadata.

Example metadata file (e.g., sample_metadata.txt):

SampleName TissueSource

Intensity.Sample1 Tissue 1

Intensity.Sample2 Tissue 1

Intensity.Sample3 Tissue 2

Intensity.Sample4 Tissue 2

```{r}
msnset_obj <- NULL
if (file.exists(SAMPLE_METADATA_FILE)) {
  cat("Loading sample metadata from:", SAMPLE_METADATA_FILE, "\n")
  sample_metadata <- read.delim(SAMPLE_METADATA_FILE, header = TRUE, sep = "\t")
  

  # Ensure sample names in metadata match intensity column names (after potential cleaning)
  # cleaned_intensity_cols <- sub(INTENSITY_COLUMNS_PATTERN, "P", intensity_cols) # Example cleaning
  # print(cleaned_intensity_cols)
  # if (!all(cleaned_intensity_cols %in% sample_metadata$SampleName)) {
  #    warning("Mismatch between intensity column names and sample metadata. Trying to proceed but check names.")
  #    # You might need more sophisticated name matching here
  # }
  # # Reorder metadata to match column order
  # sample_metadata_updated <- sample_metadata[match(cleaned_intensity_cols, sample_metadata$SampleName), ]
  # View(sample_metadata_updated)
  # Create PhenoData
  pdata <- new("AnnotatedDataFrame", data = sample_metadata)
  rownames(pdata) <- colnames(expr_matrix_log2) # Assign column names of matrix as rownames for PhenoData

  # Create FeatureData (optional, can add protein annotations)
  fdata <- data.frame(row.names = rownames(expr_matrix_log2))
  fdata$`Potential contaminant` <- prot_data$`Potential contaminant`
  fdata$Reverse <- prot_data$Reverse
  fdata$`Q-value` <- prot_data$`Q-value`
  fdata$Score <- prot_data$Score
  # Add more columns from prot_data if needed, e.g., prot_data[, c("Gene names", "Fasta headers")]
  fdata_df <- new("AnnotatedDataFrame", data = fdata)

  # Create MSnSet object
  msnset_obj <- new("MSnSet",
                    exprs = expr_matrix_log2,
                    phenoData = pdata,
                    featureData = fdata_df)
  cat("MSnSet object created.\n")

} else {
  warning("Sample metadata file not found. Proceeding without MSnSet object. QC and Normalization might be limited.")
  # Use the log2 matrix directly if no metadata is available
  expr_data_to_process <- expr_matrix_log2
}
```

# 5. Quality Control and Data Normalization

```{r}
if (!is.null(msnset_obj)) {
  # --- Filtering (using MSnSet) ---
  # Remove potential contaminants and reverse sequences if markers are present
  if (!is.null(CONTAMINANT_MARKER) && "Potential contaminant" %in% colnames(prot_data)) {
      contam_idx <- grep(CONTAMINANT_MARKER, fData(msnset_obj)$`Potential contaminant`, fixed = TRUE)
      if (length(contam_idx) > 0) {
          msnset_obj <- msnset_obj[-contam_idx, ]
          cat("Removed", length(contam_idx), "potential contaminants.\n")
      }
  }
   if (!is.null(REVERSE_MARKER) && "Reverse" %in% colnames(prot_data)) {
       reverse_idx <- grep(REVERSE_MARKER, fData(msnset_obj)$Reverse, fixed = TRUE)
        if (length(reverse_idx) > 0) {
           msnset_obj <- msnset_obj[-reverse_idx, ]
           cat("Removed", length(reverse_idx), "reverse sequences.\n")
       }
   }

  # Filter features (proteins) with too many NAs (e.g., present in < 50% of samples in at least one group)
  # This is often done BEFORE imputation simulation. Adjust threshold as needed.
  msnset_obj <- filterNA(msnset_obj, pNA = 0.5) # Example: requires 'Condition' in pData

  # --- Normalization (using MSnSet) ---
  # Options: "median", "quantiles", "sum", "max", etc. Median or quantile are common.
  cat("Performing median normalization...\n")
  msnset_norm <- normalise(msnset_obj, method = "center.median")
  # Or: msnset_norm <- normalise(msnset_obj, method = "quantiles")

  # Extract the normalized expression matrix
  expr_norm <- exprs(msnset_norm)
  cat("Normalization complete.\n")

} else {
  # --- Normalization (using matrix directly) ---
  # Basic median centering as an example if MSnSet wasn't created
  cat("Performing median normalization on the matrix...\n")
  col_medians <- apply(expr_data_to_process, 2, median, na.rm = TRUE)
  expr_norm <- sweep(expr_data_to_process, 2, col_medians, "-") # Subtract column medians
  cat("Normalization complete.\n")

  # Note: Filtering would need to be done manually on the matrix here.
}
```

```{r}
# Save the clean, normalized data (before introducing missingness)
clean_norm_file <- file.path(OUTPUT_DIR, "normalized_data_complete.csv")
write.csv(expr_norm, file = clean_norm_file, row.names = TRUE)
cat("Saved normalized data to:", clean_norm_file, "\n")
```

# 6. Introduce Synthetic Missingness

```{r}
# Function to introduce MCAR
introduce_mcar <- function(data, proportion) {
  if (proportion == 0) return(data)
  mat <- data
  n_total <- length(mat[!is.na(mat)]) # Only consider non-missing values for proportion calculation
  n_missing <- round(n_total * proportion) # Number of missing is proportion of the total
  if (n_missing == 0 && proportion > 0) {
      warning("Calculated 0 values to make missing for MCAR proportion ", proportion)
      return(data)
  } # Catch bad returns
  na_indices <- sample(which(!is.na(mat)), n_missing) # takes sample from  data = to number of missing
  mat[na_indices] <- NA # replace those samples with NA
  return(mat)
} # consider using set.seed(5) to produce same sequence everytime function is ran

# Function to introduce MNAR (based on value intensity)
# Values below a certain quantile are set to NA
introduce_mnar <- function(data, proportion) {
   if (proportion == 0) return(data)
   mat <- data
   # Determine the quantile threshold based on non-missing values
   threshold <- quantile(mat, probs = proportion, na.rm = TRUE)
   if (is.na(threshold)) {
       warning("Could not determine MNAR threshold for proportion ", proportion)
       return(data)
   }
   mat[mat < threshold] <- NA # Remove data that is less than threshold
   return(mat)
}


# Function to introduce MAR (simplified: missingness depends on row means)
# Lower mean intensity rows are more likely to have values missing
# introduce_mar <- function(data, proportion) {
#   if (proportion == 0) return(data)
#   mat <- data
#   n_total_obs <- sum(!is.na(mat))
#   target_missing <- round(n_total_obs * proportion)
#   current_missing <- sum(is.na(mat))
#   n_to_add <- target_missing - current_missing
# 
#   if (n_to_add <= 0) {
#       # If the data already has enough or more missing values than requested, just return it.
#       # Or, if proportion is 0.
#       if (proportion > 0) warning("Target MAR missingness already met or exceeded. No MAR values added for proportion ", proportion)
#       return(data)
#   }
# 
#   # Calculate row means (excluding existing NAs)
#   row_means <- rowMeans(mat, na.rm = TRUE)
#   # Inverse probability: lower mean -> higher probability of missingness
#   # Add a small epsilon to avoid division by zero if a mean is 0
#   prob_weights <- 1 / (row_means + 1e-6)
#   # Normalize weights
#   prob_weights[is.infinite(prob_weights)] <- max(prob_weights[is.finite(prob_weights)]) * 10 # Handle potential Inf
#   prob_weights[is.na(prob_weights)] <- 0 # Rows with all NAs shouldn't be sampled
# 
#   # Get indices of observed values
#   observed_indices <- which(!is.na(mat), arr.ind = TRUE)
#   if (nrow(observed_indices) == 0) {
#       warning("No observed values left to introduce MAR missingness.")
#       return(mat)
#   }
#   
#   # Get the corresponding row index for each observed linear index
#   observed_row_indices <- row(mat)[observed_indices]
# 
#   # Get weights corresponding to each observed value based on its row's mean
#   weights_for_sampling <- prob_weights[observed_row_indices]
#   
#   # Ensure weight_of_sampling has the correct length adn no invalid values
#   if(length(weights_for_sampling) != length(observed_indices)){
#       stop("Internal error: Length mismatch between observed indices and weights.")
#   }
#   weights_for_sampling[is.na(weights_for_sampling)] <- 0 # Ensure no NA weights
# 
#    # Check if we have enough valid weights and indices to sample from
#   valid_indices_for_sampling <- which(weights_for_sampling > 0)
#   if (length(valid_indices_for_sampling) < n_to_add) {
#       warning("Not enough valid candidates to introduce the desired number of MAR NAs. Adding as many as possible.")
#       n_to_add <- length(valid_indices_for_sampling)
#   }
#    if(n_to_add <= 0){
#        warning("No values could be selected for MAR.")
#        return(mat)
#    }
# 
#   # Sample indices to set to NA, weighted by inverse row mean
#   # The population to sample from is observed_linear_indices[valid_candidates_mask]
#   # The probabilities correspond to weights_for_sampling[valid_candidates_mask]
#   indices_to_make_na <- sample(
#     x = observed_indices[valid_indices_for_sampling],
#     size = n_to_add,
#     prob = weights_for_sampling[valid_indices_for_sampling],
#     replace = FALSE
#   )
#   
# 
#   mat[indices_to_make_na] <- NA
#   return(mat)
# }

introduce_mar <- function(data, proportion) {
  if (proportion == 0) return(data)
  mat <- data
  n_total_obs <- sum(!is.na(mat))
  target_missing <- round(n_total_obs * proportion) # Target number of NAs based on observed values
  current_missing <- sum(is.na(mat))
  n_to_add <- target_missing - current_missing # How many more NAs we need to add

  if (n_to_add <= 0) {
      # If the data already has enough or more missing values than requested
      if (proportion > 0) warning("Target MAR missingness already met or exceeded. No MAR values added for proportion ", proportion)
      return(data)
  }

  # Calculate row means (excluding existing NAs)
  row_means <- rowMeans(mat, na.rm = TRUE)
  # Inverse probability: lower mean -> higher probability of missingness
  # Add a small epsilon to avoid division by zero if a mean is 0 or negative (if data not log-transformed properly)
  prob_weights_rows <- 1 / (row_means + 1e-6)

  # Handle potential Inf/NA/negative weights for rows (e.g., if row_means was 0 or negative)
  prob_weights_rows[is.infinite(prob_weights_rows)] <- 0 # Set Inf weights to 0 probability
  prob_weights_rows[is.na(prob_weights_rows)] <- 0      # Set NA weights to 0 probability
  prob_weights_rows[prob_weights_rows < 0] <- 0        # Set negative weights to 0 probability

  # Get linear indices of all currently observed values
  observed_linear_indices <- which(!is.na(mat))

  if (length(observed_linear_indices) == 0) {
      warning("No observed values left to introduce MAR missingness.")
      return(mat)
  }

  # Get the corresponding row index for each observed linear index
  observed_row_indices <- row(mat)[observed_linear_indices]

  # Get the probability weight for each observed value based on its row's weight
  weights_for_sampling <- prob_weights_rows[observed_row_indices]

  # Ensure weights_for_sampling has the correct length and no invalid values
  if(length(weights_for_sampling) != length(observed_linear_indices)){
      stop("Internal error: Length mismatch between observed indices and weights.") # Should not happen
  }
   weights_for_sampling[is.na(weights_for_sampling)] <- 0 # Final check for NAs

  # Check if there are any valid candidates left to sample from
  valid_candidates_mask <- weights_for_sampling > 0
  num_valid_candidates <- sum(valid_candidates_mask)

  if (num_valid_candidates == 0) {
       warning("No valid candidates (with positive probability) found to introduce MAR missingness for proportion ", proportion)
       return(mat)
  }

  # Adjust n_to_add if it's more than the number of valid candidates
  if (n_to_add > num_valid_candidates) {
      warning("Not enough valid candidates to introduce the desired number of MAR NAs (", n_to_add, "). Adding ", num_valid_candidates, " NAs instead for proportion ", proportion)
      n_to_add <- num_valid_candidates
  }

  # Sample linear indices from the valid candidates, using their corresponding weights
  # The population to sample from is observed_linear_indices[valid_candidates_mask]
  # The probabilities correspond to weights_for_sampling[valid_candidates_mask]
  indices_to_make_na <- sample(
      x = observed_linear_indices[valid_candidates_mask],
      size = n_to_add,
      prob = weights_for_sampling[valid_candidates_mask],
      replace = FALSE
  )

  # Introduce NAs at the sampled indices
  mat[indices_to_make_na] <- NA
  return(mat)
}

cat("Loaded functions.")
```

```{r}
# Generate datasets with different missingness patterns and proportions
missing_proportions <- c(0.1, 0.2, 0.3) # 10%, 20%, 30%
missing_types <- c("MCAR", "MNAR", "MAR")

datasets_missing <- list()

for (prop in missing_proportions) {
  for (type in missing_types) {
    cat("Generating missing data: Proportion =", prop, ", Type =", type, "\n")
    dataset_name <- paste0("missing_", type, "_", prop * 100)
    temp_data <- expr_norm # Start with the clean normalized data

    if (type == "MCAR") {
      datasets_missing[[dataset_name]] <- introduce_mcar(temp_data, prop)
    } else if (type == "MNAR") {
      datasets_missing[[dataset_name]] <- introduce_mnar(temp_data, prop)
    } else if (type == "MAR") {
      # Note: This MAR simulation is basic. Real MAR might depend on other variables.
      datasets_missing[[dataset_name]] <- introduce_mar(temp_data, prop)
    }

    # Save the dataset with missing values
    missing_file <- file.path(OUTPUT_DIR, paste0(dataset_name, ".csv"))
    write.csv(datasets_missing[[dataset_name]], file = missing_file, row.names = TRUE)
    cat("Saved missing data to:", missing_file, "\n")
  }
}

cat("Created .csv files with missing datasets.")
```
